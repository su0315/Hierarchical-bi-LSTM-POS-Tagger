{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1prcdoUugyV6JV_sTa1Wi9iipQRqU8BU1",
      "authorship_tag": "ABX9TyPpezUbQbucR5OWhKtOEsl5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xNst021NxUUo"
      },
      "outputs": [],
      "source": [
        "!pip install -q polyglot\n",
        "!pip install -q conllu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import numpy as np\n",
        "from polyglot.mapping import Embedding\n",
        "from conllu import parse\n",
        "from tqdm import tqdm\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "ZoX47ks-E1WF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/MyDrive/DL for NLP project/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLNhu2-IHNgx",
        "outputId": "946fc016-9284-45e0-8c80-7f396309ecd9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/DL for NLP project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeds = Embedding.from_glove('polyglot/en.polyglot.txt')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "BPWbuouYFggs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"languages/en/en-ud-train.conllu\") as file:\n",
        "    train_data = parse(file.read())\n",
        "with open(\"languages/en/en-ud-dev.conllu\") as file:\n",
        "    dev_data = parse(file.read())\n",
        "with open(\"languages/en/en-ud-test.conllu\") as file:\n",
        "    test_data = parse(file.read())"
      ],
      "metadata": {
        "id": "oqxzY8Ugsk-y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_indexes(data):\n",
        "    w2i = {}\n",
        "    c2i = {}\n",
        "    l2i = {}\n",
        "    w2i[\"_UNK\"] = 0\n",
        "    c2i[\"_UNK\"] = 0\n",
        "    c2i[\"<w>\"] = 1\n",
        "    c2i[\"</w>\"] = 2\n",
        "    for sentence in data:\n",
        "        for token in sentence:\n",
        "            word = token['form'].lower()\n",
        "            if word not in w2i:\n",
        "                w2i[word] = len(w2i)\n",
        "            for character in list(word):\n",
        "                if character not in c2i:\n",
        "                    c2i[character] = len(c2i)\n",
        "            if token['upos'] not in l2i:\n",
        "                l2i[token['upos']] = len(l2i)\n",
        "    return w2i, c2i, l2i\n",
        "w2i, c2i, l2i = build_indexes(train_data)"
      ],
      "metadata": {
        "id": "uxW2uRQjPz8l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_embedding_matrix(w2i, embeds):\n",
        "    embedding_matrix = torch.FloatTensor(size=(len(w2i), 64))\n",
        "    for word, index in w2i.items():\n",
        "        embedding = embeds.get(word.lower())\n",
        "        if embedding is not None:\n",
        "            embedding_matrix[index] = torch.FloatTensor(embedding)\n",
        "        else:\n",
        "            embedding_matrix[index] = torch.rand((1,64))\n",
        "    return embedding_matrix\n",
        "embedding_matrix = build_embedding_matrix(w2i, embeds)"
      ],
      "metadata": {
        "id": "KT-rHrxLLc5X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqbin = {word : int(np.log(frequency)) for word, frequency in Counter([token['form'].lower() for sentence in train_data for token in sentence]).items()}"
      ],
      "metadata": {
        "id": "jcpMtchklVBn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Character_Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Character_Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=100)\n",
        "        self.bilstm = nn.LSTM(input_size=100, hidden_size=100, num_layers=1, bidirectional=True)\n",
        "\n",
        "    def forward(self, chars:torch.tensor): # chars = (N_CHARS,)\n",
        "        embedded = self.embedding(chars)\n",
        "        _, (final_hidden, _) = self.bilstm(embedded.view(len(chars), 1, 100))\n",
        "        return final_hidden.view(-1) # (2*HIDDEN,)"
      ],
      "metadata": {
        "id": "dzXtjgg2IHgN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class POS_Tagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_matrix, vocab_size, freq_max):\n",
        "        super(POS_Tagger, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix).requires_grad_(True)\n",
        "        self.characterbased = Character_Encoder(vocab_size).to(device)\n",
        "        self.bilstm = nn.LSTM(input_size=264, hidden_size=100, num_layers=1, bidirectional=True)\n",
        "        self.pos_tagger = nn.Linear(in_features=200, out_features=17)\n",
        "        self.freqbin = nn.Linear(in_features=200, out_features=freq_max)\n",
        "\n",
        "    def forward(self, tokens:torch.tensor, char_lists:list): # tokens = (N_TOKENS, 64), char_lists = List[List[int]]\n",
        "        embedded = self.embedding(tokens)\n",
        "        concatted = torch.zeros((len(embedded), 264), device=device) # concatted = (N_TOKENS, 264)\n",
        "        for i, char_list in enumerate(char_lists):\n",
        "            encoded_token = self.characterbased(torch.tensor(char_list, device=device))\n",
        "            concatted[i] = torch.concat((embedded[i], encoded_token))\n",
        "        bilstm_out, _ = self.bilstm(concatted.view(len(embedded), 1, 264))\n",
        "        pos_tags = self.pos_tagger(bilstm_out.view(len(embedded), 200))\n",
        "        freq = self.freqbin(bilstm_out.view(len(embedded), 200))\n",
        "        return pos_tags, freq"
      ],
      "metadata": {
        "id": "qdAh5E-UT69_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensorize_data(sentence):\n",
        "    tokens_list = []\n",
        "    char_lists = []\n",
        "    pos_tag_list = []\n",
        "    freq_list = []\n",
        "    for token in sentence:\n",
        "        word = token['form'].lower()\n",
        "        tokens_list.append(w2i[word] if word in w2i else 0)\n",
        "        char_list = [c2i['<w>']]\n",
        "        for char in word:\n",
        "            char_list.append(c2i[char] if char in c2i else 0)\n",
        "        char_list.append(c2i['</w>'])\n",
        "        char_lists.append(char_list)\n",
        "        pos_tag_list.append(l2i[token['upos']])\n",
        "        freq_list.append(freqbin[word] if word in freqbin else 0)\n",
        "    tokens = torch.LongTensor(tokens_list).to(device)\n",
        "    pos_gold = torch.LongTensor(pos_tag_list).to(device)\n",
        "    freq_gold = torch.LongTensor(freq_list).to(device)\n",
        "    return tokens, char_lists, pos_gold, freq_gold"
      ],
      "metadata": {
        "id": "3vhVMI1RY3UO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        accuracy = 0\n",
        "        n_tokens = 0\n",
        "        for sentence in tqdm(data, desc=\"Evaluation\"):\n",
        "            tokens, char_lists, golden, _ = tensorize_data(sentence)\n",
        "            pred, _ = model(tokens, char_lists)\n",
        "            pred_label = torch.argmax(pred, dim=1)\n",
        "            accuracy += torch.sum(pred_label == golden)\n",
        "            n_tokens += len(tokens)\n",
        "    return accuracy/n_tokens"
      ],
      "metadata": {
        "id": "aSKkG47aZ2RV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 20\n",
        "report_every = 1\n",
        "learning_rate = 0.1\n",
        "variance = 0.2 #TODO######################################################################################\n",
        "\n",
        "model = POS_Tagger(embedding_matrix, len(c2i), max(freqbin.values())+1).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for sentence in tqdm(train_data, desc=\"Training  \"):\n",
        "        optimizer.zero_grad()\n",
        "        tokens, char_lists, pos_gold, freq_gold = tensorize_data(sentence)\n",
        "        pos_pred, freq_pred = model(tokens, char_lists)\n",
        "        loss = criterion(pos_pred, pos_gold) + criterion(freq_pred, freq_gold)\n",
        "        total_loss += loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Testing    \n",
        "    if ((epoch + 1) % report_every) == 0:\n",
        "        train_accuracy = eval(model, train_data)\n",
        "        dev_accuracy = eval(model, dev_data)\n",
        "        print('epoch: %d, loss: %.4f, train acc: %.2f, dev acc: %.2f' % (epoch, total_loss/len(train_data), train_accuracy, dev_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "XgdnK4FrQgdg",
        "outputId": "5213ce88-bef1-4ce7-f1a7-0344d12194a9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training  : 100%|██████████| 12543/12543 [03:10<00:00, 66.00it/s]\n",
            "Evaluation: 100%|██████████| 12543/12543 [01:06<00:00, 188.02it/s]\n",
            "Evaluation:   0%|          | 1/2002 [00:00<00:09, 204.78it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-1715bf042d44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreport_every\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mdev_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch: %d, loss: %.4f, train acc: %.2f, dev acc: %.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-28a794b6071a>\u001b[0m in \u001b[0;36meval\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mn_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_lists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-dbc5d790a3c1>\u001b[0m in \u001b[0;36mtensorize_data\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mchar_lists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpos_tag_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'upos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mfreq_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreqbin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpos_gold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tag_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'jurists'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = eval(model, test_data)\n",
        "print(f\"\\nTest accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "LtpX66r6aufr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db21e203-f40d-43d4-9c5d-89b05d02e13e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 2077/2077 [00:08<00:00, 242.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test accuracy: 0.905841588973999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}